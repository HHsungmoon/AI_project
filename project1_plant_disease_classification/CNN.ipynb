{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import time\n",
    "import copy\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "    \n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 크기 조정 (64,64) , 이미지를 텐서 형태로 변환하고 0~1로 정규화\n",
    "transform_base = transforms.Compose([transforms.Resize((64,64)),transforms.ToTensor()])\n",
    "\n",
    "train_dataset = ImageFolder(root='./splited/train/', transform = transform_base)\n",
    "val_dataset = ImageFolder(root='./splited/val/', transform = transform_base)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle = True, num_workers=4)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size = BATCH_SIZE, shuffle = True, num_workers=4)\n",
    "\n",
    "#train_loader 데이터 형식 (data,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolution 연산 3->16->32->64\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        \n",
    "        self.conv1 = torch.nn.Conv2d(3, 16, 3, stride=1, padding=1)\n",
    "        self.conv2 = torch.nn.Conv2d(16, 32, 3, stride=1, padding=1)\n",
    "        self.conv3 = torch.nn.Conv2d(32, 64, 3, stride=1, padding=1)\n",
    "        \n",
    "        self.pool = torch.nn.MaxPool2d(2,2)\n",
    "        \n",
    "        self.fc1 = torch.nn.Linear(4096, 512)  # conv 연산을 3번 진행 하면서 pool링 과정을 3번 거치면 64,64 -> 8,8로 축소된다.\\\n",
    "        self.fc2 = torch.nn.Linear(512, 128)\n",
    "        self.fc3 = torch.nn.Linear(128, 33)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = F.dropout(x, p=0.25,training=self.training)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = F.dropout(x, p=0.25,training=self.training)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = F.dropout(x, p=0.25,training=self.training)\n",
    "        \n",
    "        x = x.view(-1, 4096)  \n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.fc3(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn = CNN().to(DEVICE)\n",
    "optimizer = optim.Adam(model_cnn.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer):\n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, (data,target) in enumerate(train_loader):\n",
    "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(data)\n",
    "        \n",
    "        loss = F.cross_entropy(output, target)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "            output = model(data)\n",
    "            \n",
    "            test_loss += F.cross_entropy(output, target, reduction='sum').item()\n",
    "            \n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- epoch 1 ----------------\n",
      "train Loss: 2.3379, Accuracy: 36.48%\n",
      "val Loss: 2.3343, Accuracy: 36.89%\n",
      "Completed in 1m 6s\n",
      "-------------- epoch 2 ----------------\n",
      "train Loss: 1.5925, Accuracy: 54.93%\n",
      "val Loss: 1.6020, Accuracy: 55.08%\n",
      "Completed in 1m 6s\n",
      "-------------- epoch 3 ----------------\n",
      "train Loss: 1.2725, Accuracy: 63.86%\n",
      "val Loss: 1.2964, Accuracy: 63.47%\n",
      "Completed in 1m 7s\n",
      "-------------- epoch 4 ----------------\n",
      "train Loss: 1.0525, Accuracy: 68.76%\n",
      "val Loss: 1.0847, Accuracy: 67.68%\n",
      "Completed in 1m 7s\n",
      "-------------- epoch 5 ----------------\n",
      "train Loss: 0.8612, Accuracy: 74.11%\n",
      "val Loss: 0.8965, Accuracy: 73.25%\n",
      "Completed in 1m 6s\n",
      "-------------- epoch 6 ----------------\n",
      "train Loss: 0.7431, Accuracy: 77.59%\n",
      "val Loss: 0.7899, Accuracy: 76.09%\n",
      "Completed in 1m 6s\n",
      "-------------- epoch 7 ----------------\n",
      "train Loss: 0.6522, Accuracy: 79.71%\n",
      "val Loss: 0.7031, Accuracy: 78.57%\n",
      "Completed in 1m 6s\n",
      "-------------- epoch 8 ----------------\n",
      "train Loss: 0.5927, Accuracy: 82.03%\n",
      "val Loss: 0.6503, Accuracy: 80.09%\n",
      "Completed in 1m 6s\n",
      "-------------- epoch 9 ----------------\n",
      "train Loss: 0.5716, Accuracy: 82.38%\n",
      "val Loss: 0.6253, Accuracy: 80.64%\n",
      "Completed in 1m 7s\n",
      "-------------- epoch 10 ----------------\n",
      "train Loss: 0.4956, Accuracy: 84.13%\n",
      "val Loss: 0.5538, Accuracy: 82.33%\n",
      "Completed in 1m 6s\n",
      "-------------- epoch 11 ----------------\n",
      "train Loss: 0.4820, Accuracy: 84.40%\n",
      "val Loss: 0.5524, Accuracy: 82.20%\n",
      "Completed in 1m 6s\n",
      "-------------- epoch 12 ----------------\n",
      "train Loss: 0.4175, Accuracy: 87.14%\n",
      "val Loss: 0.4859, Accuracy: 84.59%\n",
      "Completed in 1m 6s\n",
      "-------------- epoch 13 ----------------\n",
      "train Loss: 0.3949, Accuracy: 87.49%\n",
      "val Loss: 0.4677, Accuracy: 85.07%\n",
      "Completed in 1m 7s\n",
      "-------------- epoch 14 ----------------\n",
      "train Loss: 0.3793, Accuracy: 88.14%\n",
      "val Loss: 0.4551, Accuracy: 85.94%\n",
      "Completed in 1m 6s\n",
      "-------------- epoch 15 ----------------\n",
      "train Loss: 0.3791, Accuracy: 87.94%\n",
      "val Loss: 0.4634, Accuracy: 85.30%\n",
      "Completed in 1m 5s\n",
      "-------------- epoch 16 ----------------\n",
      "train Loss: 0.3447, Accuracy: 89.11%\n",
      "val Loss: 0.4342, Accuracy: 86.41%\n",
      "Completed in 1m 6s\n",
      "-------------- epoch 17 ----------------\n",
      "train Loss: 0.3006, Accuracy: 90.26%\n",
      "val Loss: 0.3905, Accuracy: 86.96%\n",
      "Completed in 1m 5s\n",
      "-------------- epoch 18 ----------------\n",
      "train Loss: 0.3114, Accuracy: 90.29%\n",
      "val Loss: 0.4023, Accuracy: 87.18%\n",
      "Completed in 1m 6s\n",
      "-------------- epoch 19 ----------------\n",
      "train Loss: 0.2940, Accuracy: 90.60%\n",
      "val Loss: 0.3916, Accuracy: 87.16%\n",
      "Completed in 1m 5s\n",
      "-------------- epoch 20 ----------------\n",
      "train Loss: 0.2538, Accuracy: 92.04%\n",
      "val Loss: 0.3517, Accuracy: 88.53%\n",
      "Completed in 1m 5s\n"
     ]
    }
   ],
   "source": [
    "def train_baseline(model ,train_loader, val_loader, optimizer, num_epochs = 30):\n",
    "    best_acc = 0.0  \n",
    "    best_model_wts = copy.deepcopy(model.state_dict()) \n",
    " \n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        since = time.time()  \n",
    "        train(model, train_loader, optimizer)\n",
    "        train_loss, train_acc = evaluate(model, train_loader) \n",
    "        val_loss, val_acc = evaluate(model, val_loader)\n",
    "        \n",
    "        if val_acc > best_acc: \n",
    "            best_acc = val_acc \n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        \n",
    "        time_elapsed = time.time() - since \n",
    "        print('-------------- epoch {} ----------------'.format(epoch))\n",
    "        print('train Loss: {:.4f}, Accuracy: {:.2f}%'.format(train_loss, train_acc))   \n",
    "        print('val Loss: {:.4f}, Accuracy: {:.2f}%'.format(val_loss, val_acc))\n",
    "        print('Completed in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60)) \n",
    "    model.load_state_dict(best_model_wts)  \n",
    "    return model\n",
    " \n",
    "\n",
    "base = train_baseline(model_cnn, train_loader, val_loader, optimizer, EPOCHS)  \t #(16)\n",
    "torch.save(base,'baseline.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
